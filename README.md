Ce README est en franÃ§ais. Pour la version anglaise, voir [README_en.md](README_en.md).

# AeroStream â€“ SystÃ¨me de classification automatique des avis clients

## Contexte du projet

AeroStream souhaite dÃ©velopper un systÃ¨me intelligent capable de classifier automatiquement les avis clients relatifs aux services des compagnies aÃ©riennes. Lâ€™objectif principal est dâ€™analyser le niveau de satisfaction des clients Ã  partir des donnÃ©es textuelles issues des avis utilisateurs.

Ce projet combine NLP, machine learning, bases vectorielles et visualisation interactive pour fournir des insights en temps rÃ©el sur la satisfaction des clients.

---

## Objectifs

Le systÃ¨me a pour but de :

- Collecter et prÃ©traiter les avis clients.
- Analyser automatiquement le sentiment et la satisfaction.
- GÃ©nÃ©rer des indicateurs de performance par compagnie aÃ©rienne.
- Visualiser les rÃ©sultats via un tableau de bord interactif.

---

## Pipeline Batch

Le pipeline batch permet de prÃ©parer et traiter les donnÃ©es historiques et comprend les Ã©tapes suivantes :

- **Chargement des donnÃ©es** :Import des datasets dâ€™avis clients depuis Hugging Face.
- **Analyse exploratoire des donnÃ©es (EDA)**: Ã‰tude des distributions, des classes et des statistiques principales.
- **Nettoyage des donnÃ©es**: Gestion des doublons, valeurs manquantes et nettoyage du texte.
- **GÃ©nÃ©ration des embeddings**: Transformation des textes en vecteurs Ã  lâ€™aide de modÃ¨les NLP (Sentence Transformers).
- **Stockage des mÃ©tadonnÃ©es et embeddings**: Sauvegarde des labels et vecteurs dans une base vectorielle ChromaDB, avec distinction des collections pour donnÃ©es dâ€™entraÃ®nement et de test.
- **EntraÃ®nement et Ã©valuation des modÃ¨les**: Construction des modÃ¨les de classification et sÃ©lection du meilleur modÃ¨le pour les prÃ©dictions futures.
- **DÃ©ploiement via API REST**: Le modÃ¨le entraÃ®nÃ© est exposÃ© pour des requÃªtes en production.

---

## Pipeline Streaming

Le pipeline streaming permet de traiter les avis clients en quasi-temps rÃ©el :

- **RÃ©cupÃ©ration des donnÃ©es :** Collecte des avis clients via lâ€™API en micro-batch.
- **PrÃ©paration des donnÃ©es :** Nettoyage et prÃ©traitement des nouveaux avis pour prÃ©diction.
- **Stockage des rÃ©sultats :** Enregistrement des prÃ©dictions dans une base PostgreSQL.
- **AgrÃ©gation et KPI :**
    - Nombre de tweets par compagnie aÃ©rienne
    - RÃ©partition des sentiments par compagnie
    - Taux de satisfaction par compagnie
    - Identification des principales causes de tweets nÃ©gatifs
- **Visualisation :** Tableau de bord interactif Streamlit affichant les KPI principaux, mis Ã  jour automatiquement Ã  chaque rÃ©cupÃ©ration des donnÃ©es.
- **Automatisation :** Orchestration complÃ¨te via Airflow, avec exÃ©cution programmÃ©e toutes les minutes.

---

## Technologies utilisÃ©es

- **Python** pour le traitement et le ML
- **Docker** pour la dockerisation de l'application
- **Sentence Transformers** pour le NLP
- **ChromaDB** pour la gestion des embeddings
- **PostgreSQL** pour le stockage des rÃ©sultats
- **Streamlit** pour le dashboard interactif
- **Airflow** pour lâ€™orchestration du pipeline

---

## Avantages du systÃ¨me

- Analyse en temps rÃ©el de la satisfaction client.
- Centralisation des donnÃ©es historiques et nouvelles dans un mÃªme systÃ¨me.
- Visualisation claire et interactive des KPI clÃ©s.
- Automatisation complÃ¨te pour un suivi continu de la satisfaction des clients.

---

## Installation

### PrÃ©requis

Assurez-vous dâ€™avoir installÃ© :

- Git
- Docker
- Docker Compose

### 1. Cloner le dÃ©pÃ´t

```Bash
git clone https://github.com/anass17/AeroStream.git
cd AeroStream
```

### 2. GÃ©nÃ©rer le fichier `.env`

- CrÃ©er le fichier `.env` Ã  partir de lâ€™exemple fourni :

```Bash
cp .env.example .env
```

Ensuite, ouvrez le fichier `.env` et adaptez les variables si nÃ©cessaire.

### 3. Construire et lancer les services Docker

- Construire les images Docker :

```Bash
docker-compose build
```

- DÃ©marrer tous les services :

```Bash
docker-compose up -d
```

- VÃ©rifier que les conteneurs sont bien lancÃ©s :

```Bash
docker-compose ps
```

### 4. CrÃ©er la base de donnÃ©es PostgreSQL

- AccÃ©der au conteneur PostgreSQL :

```Bash
docker exec -it aerostream-postgres psql -U postgres 
```

- CrÃ©er la base de donnÃ©es :

```Bash
CREATE DATABASE aerostream;
```

- VÃ©rifier la crÃ©ation :

```Bash
\l
```

- Quitter PostgreSQL :

```Bash
\q
```

### 5. CrÃ©er un utilisateur Airflow

- Supprimer l'utilisateur `admin`

```Bash
docker exec -it aerostream-airflow airflow users delete --username admin
```

- CrÃ©er un nouveau utilisateur

```Bash
docker exec -it aerostream-airflow airflow users create --username admin  --firstname Admin --lastname User --role Admin --email admin --password admin
```

Modifiez vos identifiants selon vos prÃ©fÃ©rences.

### 6. VÃ©rifier Airflow et les DAGs

- AccÃ©der Ã  lâ€™interface Airflow :

```Bash
URL : http://localhost:8080
```

### 7. VÃ©rifier lâ€™API

- Tester que lâ€™API est bien accessible :

```Bash
curl http://localhost:8000/
```

- AccÃ©der Ã  la documentation de l'API

```
http://localhost:8000/docs
```

### 8. VÃ©rifier le dashboard Streamlit

- AccÃ©der au dashboard :

```
http://localhost:8501
```

---

## Structure des fichiers

```
ğŸ“ AeroStream
â”‚
â”œâ”€â”€ ğŸ“ notebooks
â”‚   â”œâ”€â”€ ğŸ“„ 01_loading.ipynb             # Charger les donnÃ©es brutes
â”‚   â”œâ”€â”€ ğŸ“„ 02_eda.ipynb                 # Analyse exploratoire des donnÃ©es (EDA)
â”‚   â”œâ”€â”€ ğŸ“„ 03_preprocessing.ipynb       # Nettoyage et prÃ©traitement des donnÃ©es
â”‚   â”œâ”€â”€ ğŸ“„ 04_embeddings.ipynb          # GÃ©nÃ©ration des vecteurs d'embeddings
â”‚   â”œâ”€â”€ ğŸ“„ 05_storage_chroma_db.ipynb   # Stockage des embeddings dans ChromaDB
â”‚   â””â”€â”€ ğŸ“„ 06_model_training.ipynb      # EntraÃ®nement et Ã‰valuation des modÃ¨les ML
â”‚
â”œâ”€â”€ ğŸ“ data
â”‚   â”œâ”€â”€ ğŸ“ raw                          # DonnÃ©es brutes
â”‚   â”œâ”€â”€ ğŸ“ processed                    # DonnÃ©es nettoyÃ©es
â”‚   â”œâ”€â”€ ğŸ“ embeddings                   # Vecteurs dâ€™embeddings
â”‚   â””â”€â”€ ğŸ“ chromaDB                     # Collections stockÃ©es dans ChromaDB
â”‚
â”œâ”€â”€ ğŸ“ api
â”‚   â””â”€â”€ ğŸ“ routers                      # DÃ©finition des routes de l'API
â”‚
â”œâ”€â”€ ğŸ“ dashboard
â”‚   â”œâ”€â”€ ğŸ“ components                   # Composants rÃ©utilisables pour l'interface
â”‚   â”œâ”€â”€ ğŸ“ extraction                   # Logique d'extraction des donnÃ©es
â”‚   â”œâ”€â”€ ğŸ“ pages                        # Pages du tableau de bord
â”‚   â””â”€â”€ ğŸ“„ app.py                       
â”‚
â”œâ”€â”€ ğŸ“ airflow
â”‚   â””â”€â”€ ğŸ“ dags
â”‚       â”œâ”€â”€ ğŸ“ tasks                            # TÃ¢ches individuelles des DAGs
â”‚       â””â”€â”€ ğŸ“„ aerostream_pipeline_dag.py       # DAG principal pour Airflow
â”‚
â”œâ”€â”€ ğŸ“ models
â”‚   â”œâ”€â”€ ğŸ“ encoders                     # ModÃ¨les d'encodage
â”‚   â””â”€â”€ ğŸ“ ml                           # ModÃ¨les de machine learning
â”‚
â”œâ”€â”€ ğŸ“ docker                           # Dockerfiles
â”œâ”€â”€ ğŸ“ docs                              
â”œâ”€â”€ ğŸ“ pgdata                           # Fichiers de donnÃ©es PostgreSQL
â”œâ”€â”€ ğŸ“ requirements                     # DÃ©pendances de chaque docker service
â”œâ”€â”€ ğŸ“„ docker-compose.yml               
â”œâ”€â”€ ğŸ“„ .env                             
â”œâ”€â”€ ğŸ“„ README.md                        
â”œâ”€â”€ ğŸ“„ README_en.md                     # La version anglaise de README
â””â”€â”€ ğŸ“„ .gitignore                     
```

---

## Visualisations

### Interface Streamlit

![Streamlit UI](https://github.com/user-attachments/assets/883039ab-2919-4c9c-a29d-1508a40f5d3e)

### Interface Airflow

![Airflow UI](https://github.com/user-attachments/assets/1ffe1001-1031-426d-b6ac-cc71b4637287)

### API Endpoints

![API](https://github.com/user-attachments/assets/b81946b5-9c6d-42f7-8a25-7b418d566255)

### Architecture

![Architecture](https://github.com/user-attachments/assets/3841e38b-63cd-468e-870d-42222abf5419)