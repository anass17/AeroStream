{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ff4b13d",
   "metadata": {},
   "source": [
    "### Génération des embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faee2f9",
   "metadata": {},
   "source": [
    "##### 1. Charger les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "110b4958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('../data/processed/data_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a32da1a",
   "metadata": {},
   "source": [
    "##### 2. Séparer les données en ensembles d'entraînement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "897f83b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train: 11680\n",
      "X_Test : 2921\n",
      "Y_Train: 11680\n",
      "Y_Test : 2921\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop('airline_sentiment', axis=1)\n",
    "y = data['airline_sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print('X_Train:', len(X_train))\n",
    "print('X_Test :', len(X_test))\n",
    "print('Y_Train:', len(y_train))\n",
    "print('Y_Test :', len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078dd683",
   "metadata": {},
   "source": [
    "##### 3. Charger le modèle `paraphrase-multilingual-MiniLM-L12-v2` avec Sentence Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36727eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71215307",
   "metadata": {},
   "source": [
    "##### 4. Générer les embeddings pour les données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f11cff0",
   "metadata": {},
   "source": [
    "- Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa0c6c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 365/365 [01:40<00:00,  3.64it/s]\n"
     ]
    }
   ],
   "source": [
    "texts = X_train['text'].tolist()\n",
    "\n",
    "train_embeddings = model.encode(\n",
    "    texts,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=True,\n",
    "    show_progress_bar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b9256c",
   "metadata": {},
   "source": [
    "- Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2504b2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 92/92 [00:45<00:00,  2.00it/s]\n"
     ]
    }
   ],
   "source": [
    "texts = X_test['text'].tolist()\n",
    "\n",
    "test_embeddings = model.encode(\n",
    "    texts,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=True,\n",
    "    show_progress_bar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e03cba5",
   "metadata": {},
   "source": [
    "##### 5. Afficher les embeddings Générés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "81a4d4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:   (11680, 384)\n",
      "Test:    (2921, 384) \n",
      "\n",
      "[[ 0.03057806  0.01824954 -0.06659513 ... -0.09728357 -0.01112673\n",
      "   0.04634745]\n",
      " [ 0.08125947  0.06308529  0.00967043 ... -0.01007925 -0.1580316\n",
      "  -0.04903226]\n",
      " [ 0.10380986  0.00310333 -0.03927619 ...  0.02882032 -0.1018984\n",
      "  -0.00109817]\n",
      " ...\n",
      " [ 0.03718933  0.00505602  0.03527729 ...  0.06018802 -0.06565111\n",
      "   0.00525965]\n",
      " [-0.00319692  0.00877186 -0.00891564 ...  0.01496773 -0.07131661\n",
      "   0.01495774]\n",
      " [ 0.01028042 -0.0467954  -0.05908336 ...  0.02119558 -0.12419796\n",
      "   0.04274945]]\n"
     ]
    }
   ],
   "source": [
    "print('Train:  ', train_embeddings.shape)\n",
    "print('Test:   ', test_embeddings.shape, '\\n')\n",
    "\n",
    "print(train_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f3e036",
   "metadata": {},
   "source": [
    "##### 6. Sauvegarder les embeddings Générés `(.npy)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bf7b8a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les embeddings ont été enregistrées\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.save('../data/embedding/train_embeddings.npy', train_embeddings)\n",
    "np.save('../data/embedding/test_embeddings.npy', test_embeddings)\n",
    "\n",
    "print('Les embeddings ont été enregistrées')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e57f65",
   "metadata": {},
   "source": [
    "##### 7. Sauvegarder les labels et identifiants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540c236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "train_metadata = pd.DataFrame()\n",
    "train_metadata['label_name'] = data[['airline_sentiment']]\n",
    "train_metadata['id'] = range(0, len(train_metadata))\n",
    "train_metadata['label'] = encoder.fit_transform(train_metadata['label_name'])\n",
    "\n",
    "\n",
    "test_metadata = pd.DataFrame()\n",
    "test_metadata['label_name'] = data[['airline_sentiment']]\n",
    "test_metadata['id'] = range(0, len(test_metadata))\n",
    "test_metadata['label'] = encoder.transform(test_metadata['label_name'])\n",
    "\n",
    "train_metadata.to_csv('../data/metadata/train_metadata.csv', index=False)\n",
    "test_metadata.to_csv('../data/metadata/test_metadata.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d5093f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train_metadata[['label', 'label_name']].drop_duplicates()\n",
    "\n",
    "classes.to_csv('../data/processed/classes.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a2e311",
   "metadata": {},
   "source": [
    "##### 8. Intialiser chromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "539bb169",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb import PersistentClient\n",
    "\n",
    "client = PersistentClient(path='../data/chroma_db')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab9a20f",
   "metadata": {},
   "source": [
    "##### 8. Créer une collection train dans ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "93934ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 5000 / 11680\n",
      "Inserted 10000 / 11680\n",
      "Inserted 11680 / 11680\n"
     ]
    }
   ],
   "source": [
    "train_collection = client.get_or_create_collection(\n",
    "    'train_collection',\n",
    "    metadata={\"description\": \"Embeddings pour données d'entraînement\"}\n",
    ")\n",
    "\n",
    "batch_size = 5000\n",
    "n = len(train_embeddings)\n",
    "\n",
    "for i in range(0, n, batch_size):\n",
    "    end = min(i + batch_size, n)\n",
    "    \n",
    "    batch_ids = [str(j) for j in list(train_metadata['id'][i: end])]\n",
    "    batch_embeddings = train_embeddings[i:end].tolist()\n",
    "    batch_metadatas = [\n",
    "        {\n",
    "            \"label\": int(train_metadata['label'][j]),\n",
    "            \"label_name\": str(train_metadata['label_name'][j])\n",
    "        } for j in range(i, end)\n",
    "    ]\n",
    "    \n",
    "    train_collection.add(\n",
    "        ids=batch_ids,\n",
    "        embeddings=batch_embeddings,\n",
    "        metadatas=batch_metadatas,\n",
    "    )\n",
    "    \n",
    "    print(f\"Inserted {end} / {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de50499",
   "metadata": {},
   "source": [
    "##### 9. Créer une collection test dans ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a7e396fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 2921 / 2921\n"
     ]
    }
   ],
   "source": [
    "test_collection = client.get_or_create_collection(\n",
    "    'test_collection',\n",
    "    metadata={\"description\": \"Embeddings pour données de test\"}\n",
    ")\n",
    "\n",
    "batch_size = 5000\n",
    "n = len(test_embeddings)\n",
    "\n",
    "for i in range(0, n, batch_size):\n",
    "    end = min(i + batch_size, n)\n",
    "    \n",
    "    batch_ids = [str(j) for j in list(test_metadata['id'][i: end])]\n",
    "    batch_embeddings = test_embeddings[i:end].tolist()\n",
    "    batch_metadatas = [\n",
    "        {\n",
    "            \"label\": int(test_metadata['label'][j]),\n",
    "            \"label_name\": str(test_metadata['label_name'][j])\n",
    "        } for j in range(i, end)\n",
    "    ]\n",
    "    \n",
    "    test_collection.add(\n",
    "        ids=batch_ids,\n",
    "        embeddings=batch_embeddings,\n",
    "        metadatas=batch_metadatas\n",
    "    )\n",
    "    \n",
    "    print(f\"Inserted {end} / {n}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
