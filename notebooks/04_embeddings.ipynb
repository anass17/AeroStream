{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ff4b13d",
   "metadata": {},
   "source": [
    "### Génération des embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faee2f9",
   "metadata": {},
   "source": [
    "##### 1. Charger les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "110b4958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_clean = pd.read_csv('../data/processed/data_clean.csv')\n",
    "data_with_mentions = pd.read_csv('../data/processed/data_with_mentions.csv')\n",
    "data_balanced_undersampling = pd.read_csv('../data/processed/data_balanced_undersampling.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a32da1a",
   "metadata": {},
   "source": [
    "##### 2. Séparer les données en ensembles d'entraînement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2de2d9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def divide_sets(data):\n",
    "    X = data.drop('airline_sentiment', axis=1)\n",
    "    y = data['airline_sentiment']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42, stratify=y)\n",
    "\n",
    "    print('X_Train:', len(X_train))\n",
    "    print('X_Test :', len(X_test))\n",
    "    print('Y_Train:', len(y_train))\n",
    "    print('Y_Test :', len(y_test))\n",
    "\n",
    "    return [X_train, X_test, y_train, y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379948b9",
   "metadata": {},
   "source": [
    "- Data 1: data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "897f83b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train: 12410\n",
      "X_Test : 2191\n",
      "Y_Train: 12410\n",
      "Y_Test : 2191\n"
     ]
    }
   ],
   "source": [
    "X_train_clean, X_test_clean, y_train_clean, y_test_clean = \\\n",
    "divide_sets(data_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96ea943",
   "metadata": {},
   "source": [
    "- Data 2: data_with_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "920996b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train: 12410\n",
      "X_Test : 2191\n",
      "Y_Train: 12410\n",
      "Y_Test : 2191\n"
     ]
    }
   ],
   "source": [
    "X_train_mentions, X_test_mentions, y_train_mentions, y_test_mentions = \\\n",
    "divide_sets(data_with_mentions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d61459",
   "metadata": {},
   "source": [
    "- Data 3: data_balanced_undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "256e3d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train: 7254\n",
      "X_Test : 1281\n",
      "Y_Train: 7254\n",
      "Y_Test : 1281\n"
     ]
    }
   ],
   "source": [
    "X_train_undersampling, X_test_undersampling, y_train_undersampling, y_test_undersampling = \\\n",
    "divide_sets(data_balanced_undersampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a9ec5c",
   "metadata": {},
   "source": [
    "##### 3. Le choix de modèles de génération d’embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39e41db",
   "metadata": {},
   "source": [
    "Parmi les meilleurs modèles de génération d’embeddings, on trouve :\n",
    "\n",
    "| Modèle              | Qualité         | Multilingue       | Vitesse |\n",
    "| ------------------- | --------------- | ----------------- | ------- |\n",
    "| BGE-large-m3        | Excellent       | Oui               | Lent |\n",
    "| E5-large-v2         | Excellent       | EN only           | Moyen |\n",
    "| Multilingual-E5     | Bien            | Oui               | Moyen |\n",
    "| GTE-large           | Bien            | EN only           | Rapide |\n",
    "| MiniLM-L12-v2       | qualité faible  | Oui               | Très rapide |\n",
    "\n",
    "\n",
    "On va utiliser `E5-large-v2` pour trouver un équilibre entre la performance et la vitesse d’entraînement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4332591",
   "metadata": {},
   "source": [
    "##### 4. Prétraitement des textes pour le modéle `E5-large-v2`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b9c380",
   "metadata": {},
   "source": [
    "Le modèle `E5-large-v2` a été entraîné sur du texte naturel (phrases réelles, majuscules, ponctuation, etc.), donc il faut garder le texte aussi proche que possible de sa forme originale,\n",
    "tout en nettoyant les erreurs mineures ou les incohérences.\n",
    "\n",
    "il est recommander d'éviter de:\n",
    "- Supprimer les stopwords: Le modèle comprend leur rôle sémantique.\n",
    "- Lemmatisation ou stemming: Cela modifie la structure linguistique et le sens.\n",
    "- Supprimer la ponctuation: La ponctuation aide à comprendre le contexte.\n",
    "- Tout mettre en minuscules (Sauf si le texte contient des majuscules aléatoires ou tout en majuscules.): Peut faire perdre des distinctions importantes (Apple ≠ apple, US ≠ us).\n",
    "- Supprimer les chiffres: Les nombres ont souvent une signification utile (dates, montants…).\n",
    "\n",
    "Il est Recommander (et parfois obligatoire) de:\n",
    "- Supprimer les espaces inutiles: Nettoyer les débuts/fin de lignes et les espaces multiples.\n",
    "- Gérer les valeurs manquantes: Remplacer les `NaN` ou textes vides par une chaîne vide.\n",
    "- Ajouter le préfixe (Obligatoire): **\"passage: \"** pour les documents, **\"query: \"** pour les requêtes.\n",
    "- Tronquer les textes très longs: Si un texte dépasse la limite (512 tokens environ), on peut le couper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078dd683",
   "metadata": {},
   "source": [
    "##### 5. Charger le modèle `intfloat/e5-large-v2` avec Sentence Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36727eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('intfloat/e5-large-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71215307",
   "metadata": {},
   "source": [
    "##### 6. Générer les embeddings pour les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "64ed42da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_embeddings(X_train, X_test, suffix):\n",
    "\n",
    "    # Générer les embeddings d'entrainement\n",
    "\n",
    "    texts = X_train['text'].tolist()\n",
    "\n",
    "    train_embeddings = model.encode(\n",
    "        texts,\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True,\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "\n",
    "    # Générer les embeddings de test\n",
    "\n",
    "    texts = X_test['text'].tolist()\n",
    "\n",
    "    test_embeddings = model.encode(\n",
    "        texts,\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True,\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "\n",
    "    # Sauvegarder les embeddings Générés (.npy)\n",
    "\n",
    "    np.save(f'../data/embedding/train_embeddings_{suffix}.npy', train_embeddings)\n",
    "    np.save(f'../data/embedding/test_embeddings_{suffix}.npy', test_embeddings)\n",
    "\n",
    "    return [train_embeddings, test_embeddings]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f11cff0",
   "metadata": {},
   "source": [
    "- Data 1: data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fa0c6c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 388/388 [21:17<00:00,  3.29s/it]\n",
      "Batches: 100%|██████████| 69/69 [02:56<00:00,  2.56s/it]\n"
     ]
    }
   ],
   "source": [
    "train_embeddings_clean, test_embeddings_clean = \\\n",
    "generate_embeddings(X_train_clean, X_test_clean, 'clean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8dcc3b",
   "metadata": {},
   "source": [
    "- Data 2: data_with_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "85f2c955",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 388/388 [19:05<00:00,  2.95s/it]\n",
      "Batches: 100%|██████████| 69/69 [08:16<00:00,  7.19s/it]\n"
     ]
    }
   ],
   "source": [
    "train_embeddings_mentions, test_embeddings_mentions = \\\n",
    "generate_embeddings(X_train_mentions, X_test_mentions, 'mentions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0e3235",
   "metadata": {},
   "source": [
    "- Data 3: data_balanced_undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "828d0982",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 227/227 [37:25<00:00,  9.89s/it]\n",
      "Batches: 100%|██████████| 41/41 [05:46<00:00,  8.44s/it]\n"
     ]
    }
   ],
   "source": [
    "train_embeddings_undersampling, test_embeddings_undersampling = \\\n",
    "generate_embeddings(X_train_undersampling, X_test_undersampling, 'undersampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e03cba5",
   "metadata": {},
   "source": [
    "##### 7. Afficher les embeddings Générés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "81a4d4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - 1: (12410, 1024)\n",
      "Test  - 1: (2191, 1024) \n",
      "\n",
      "Train - 2: (12410, 1024)\n",
      "Test  - 2: (2191, 1024) \n",
      "\n",
      "Train - 3: (7254, 1024)\n",
      "Test  - 3: (1281, 1024) \n",
      "\n",
      "[[ 0.02839299 -0.02863677  0.00565065 ... -0.02072558  0.0079131\n",
      "   0.0486407 ]\n",
      " [ 0.03700669 -0.03339322  0.04501049 ... -0.03881466  0.0141934\n",
      "   0.01910754]\n",
      " [ 0.00680762 -0.0303178   0.03598471 ... -0.03867556  0.01009593\n",
      "   0.00223314]\n",
      " ...\n",
      " [ 0.02948683 -0.04877236  0.02602102 ... -0.04681333  0.02730181\n",
      "   0.03831755]\n",
      " [ 0.01031082 -0.05356324  0.00806744 ... -0.02714521  0.03243184\n",
      "   0.03135326]\n",
      " [ 0.0027516  -0.02729725  0.02865412 ... -0.03459664  0.03529878\n",
      "   0.03521831]]\n"
     ]
    }
   ],
   "source": [
    "print('Train - 1:', train_embeddings_clean.shape)\n",
    "print('Test  - 1:', test_embeddings_clean.shape, '\\n')\n",
    "print('Train - 2:', train_embeddings_mentions.shape)\n",
    "print('Test  - 2:', test_embeddings_mentions.shape, '\\n')\n",
    "print('Train - 3:', train_embeddings_undersampling.shape)\n",
    "print('Test  - 3:', test_embeddings_undersampling.shape, '\\n')\n",
    "\n",
    "print(train_embeddings_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e57f65",
   "metadata": {},
   "source": [
    "##### 8. Sauvegarder les labels et identifiants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3aad6b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib as jb\n",
    "\n",
    "def encode_labels(y_train, y_test, suffix):\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "\n",
    "    # Metadata de l'entrainement\n",
    "\n",
    "    train_metadata = pd.DataFrame()\n",
    "    train_metadata['label_name'] = y_train\n",
    "    train_metadata['id'] = range(0, len(train_metadata))\n",
    "    train_metadata['label'] = encoder.fit_transform(train_metadata['label_name'])\n",
    "\n",
    "    # Metadata de test\n",
    "\n",
    "    test_metadata = pd.DataFrame()\n",
    "    test_metadata['label_name'] = y_test\n",
    "    test_metadata['id'] = range(0, len(test_metadata))\n",
    "    test_metadata['label'] = encoder.transform(test_metadata['label_name'])\n",
    "\n",
    "    # Sauvegarder les metadatas\n",
    "\n",
    "    train_metadata.to_csv(f'../data/metadata/train_metadata_{suffix}.csv', index=False)\n",
    "    test_metadata.to_csv(f'../data/metadata/test_metadata_{suffix}.csv', index=False)\n",
    "\n",
    "    # Sauvegarder l'encoder\n",
    "\n",
    "    jb.dump(encoder, f'../models/encoders/encoder_{suffix}.pkl')\n",
    "\n",
    "    # Afficher un message de réussi\n",
    "\n",
    "    print(\"Les métadonnées ont été générées et enregistrées.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed87cee8",
   "metadata": {},
   "source": [
    "- Data 1: data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "540c236d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les métadonnées ont été générées et enregistrées.\n"
     ]
    }
   ],
   "source": [
    "encode_labels(y_train_clean, y_test_clean, 'clean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330359e6",
   "metadata": {},
   "source": [
    "- Data 2: data_with_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "825081cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les métadonnées ont été générées et enregistrées.\n"
     ]
    }
   ],
   "source": [
    "encode_labels(y_train_mentions, y_test_mentions, 'mentions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80d8c77",
   "metadata": {},
   "source": [
    "- Data 3: data_balanced_undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bc471a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les métadonnées ont été générées et enregistrées.\n"
     ]
    }
   ],
   "source": [
    "encode_labels(y_train_undersampling, y_test_undersampling, 'undersampling')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
